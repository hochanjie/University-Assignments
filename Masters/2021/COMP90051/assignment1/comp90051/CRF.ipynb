{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path finding\n",
    "def find_min(open_dict, sink):\n",
    "    if sink in open_dict.keys():\n",
    "        return [sink, open_dict[sink][0], open_dict[sink][1]]\n",
    "    values = list(open_dict.values())\n",
    "    values.sort(key=lambda x: x[1])\n",
    "    min = values[0][0]\n",
    "    for i in open_dict.keys():\n",
    "        if open_dict[i][0] == min:\n",
    "            return [i, open_dict[i][0], open_dict[i][1]]\n",
    "\n",
    "\n",
    "def show_path(close_dict, path, sink):\n",
    "    if (sink in close_dict.keys()):\n",
    "        path.append(sink)\n",
    "        path = show_path(close_dict, path, close_dict[sink][1])\n",
    "    return path\n",
    "\n",
    "\n",
    "def find_path(g1, srce, sink):\n",
    "    path = []\n",
    "    open_dict = {srce: [0, -1]}\n",
    "    close_dict = {}\n",
    "    while len(open_dict.keys()) != 0:\n",
    "        min_key = find_min(open_dict, sink)\n",
    "        close_dict[min_key[0]] = [min_key[1], min_key[2]]  # [score, parent node]\n",
    "        if min_key[0] == sink:\n",
    "            return show_path(close_dict, path, sink)[::-1]\n",
    "        else:\n",
    "            subnodes = []\n",
    "            if min_key[0] not in g1.keys():\n",
    "                open_dict.pop(min_key[0])\n",
    "                continue\n",
    "            for i in g1[min_key[0]]:\n",
    "                subnodes.append([i[0], i[1], min_key[0]])  # [current, score, parent node]\n",
    "            for node in subnodes:\n",
    "                if node[0] in close_dict.keys():\n",
    "                    continue\n",
    "                if node[0] not in open_dict.keys():\n",
    "                    open_dict[node[0]] = [node[1], node[2]]\n",
    "                elif node[0] in open_dict.keys():\n",
    "                    if open_dict[node[0]][0] > node[1]:\n",
    "                        open_dict[node[0]][0] = node[1]\n",
    "                        open_dict[node[0]][1] = node[2]\n",
    "            open_dict.pop(min_key[0])\n",
    "    return []\n",
    "\n",
    "\n",
    "def cal_score(g1, path):\n",
    "    s = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        for j in g1[path[i]]:\n",
    "            if j[0] == path[i + 1]:\n",
    "                s += j[1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestData(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "# network graph drawing\n",
    "def createG1():\n",
    "    txt = []\n",
    "    with open(\"train.txt\") as f:\n",
    "        l = f.readline()\n",
    "        while l:\n",
    "            txt.append(list(map(int, l.split())))\n",
    "            l = f.readline()\n",
    "\n",
    "    g1 = {}\n",
    "    converted_txt = []\n",
    "    tmp = []\n",
    "    for link in txt:\n",
    "        for subset in itertools.permutations(link, 2):\n",
    "            tmp.append(subset[0])\n",
    "            tmp.append(subset[1])\n",
    "            converted_txt.append(subset)\n",
    "    train1 = pd.DataFrame(converted_txt, columns=[\"srce\", \"dest\"])\n",
    "    freq = train1.groupby([\"srce\", \"dest\"]).size().values\n",
    "    #train1['freq'] = freq\n",
    "    txt_1 = sorted(set(converted_txt))\n",
    "    df1 = pd.DataFrame(txt_1, columns=[\"srce\", \"dest\"])\n",
    "    df1['freq'] = freq\n",
    "    for points, f in zip(txt_1, freq):\n",
    "        g1[points[0]] = g1.setdefault(points[0], [])\n",
    "        g1[points[0]].append((points[1], f))\n",
    "\n",
    "    return g1, list(set(tmp)), df1\n",
    "\n",
    "def fu(g1, u):\n",
    "    return 1\n",
    "\n",
    "def getNodeScore(g1, Nu):\n",
    "    AA = 0\n",
    "    RA = 0\n",
    "    CCN = len(Nu)\n",
    "    CRA = 0\n",
    "    if len(Nu) == 0:\n",
    "        return 0, 0, 0, 0\n",
    "    for u in Nu:\n",
    "        AA += 1/np.log(len(g1[u]))\n",
    "        RA += 1/len(g1[u])\n",
    "        CCN += fu(g1, u)\n",
    "        CRA += fu(g1, u)/len(g1[u])\n",
    "    return AA, RA, CCN, CRA\n",
    "\n",
    "def Pxy(g1, x, y):\n",
    "    try:\n",
    "        Gx = g1[x]\n",
    "        Gy = g1[y]\n",
    "    except:\n",
    "        return 0, 0, 0, 0, 0, 0\n",
    "    Nx = [i[0] for i in Gx]\n",
    "    Ny = [i[0] for i in Gy]\n",
    "    NxINy = list(set(Nx) & set(Ny))\n",
    "    NxUNy = list(set(Nx + Ny))\n",
    "    AA, RA, CCN, CRA = getNodeScore(g1, NxINy)\n",
    "    cardNx = len(Nx)\n",
    "    cardNy = len(Ny)\n",
    "    PA = cardNx * cardNy\n",
    "    JC = len(NxINy)/len(NxUNy)\n",
    "    return JC, RA, AA, PA, CCN, CRA\n",
    "\n",
    "def extract_feature(g1, x, y):\n",
    "    path = find_path(g1, x, y)\n",
    "    l = len(path)\n",
    "    features = {}\n",
    "    if l == 2:\n",
    "        JC, RA, AA, PA, CCN, CRA = Pxy(g1, x, y)\n",
    "        features = {\n",
    "            'JC': JC,\n",
    "            'RA': RA,\n",
    "            'AA': AA,\n",
    "            'PA': PA,\n",
    "            'CCN': CCN,\n",
    "        }\n",
    "    elif l > 2:\n",
    "        features = {}\n",
    "        for i in range(l - 1):\n",
    "            JC, RA, AA, PA, CCN, CRA = Pxy(g1, path[i], path[i+1])\n",
    "            features.update({\n",
    "                'JC-'+str(path[i])+'-'+str(path[i+1]): JC,\n",
    "                'RA-'+str(path[i])+'-'+str(path[i+1]): RA,\n",
    "                'AA-'+str(path[i])+'-'+str(path[i+1]): AA,\n",
    "                'PA-'+str(path[i])+'-'+str(path[i+1]): PA,\n",
    "                'CCN-'+str(path[i])+'-'+str(path[i+1]): CCN,\n",
    "            })\n",
    "    else:\n",
    "        features['FAKE'] = True\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test = loadTestData('test-public.csv')\n",
    "\n",
    "# Load and Preprocess data\n",
    "G1, V, df1 = createG1()\n",
    "\n",
    "X = df1[['srce', 'dest']]\n",
    "y = df1['freq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "X_train1 = [extract_feature(G1, i[0], i[1]) for idx, i in X_train.iterrows()]\n",
    "y_train1 = [i for i in y_train]\n",
    "\n",
    "X_test1 = [extract_feature(G1, i[0], i[1]) for idx, i in X_test.iterrows()]\n",
    "y_test1 = [i for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-9e21d555ae28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mall_possible_transitions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn_crfsuite\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_dev, y_dev)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myseq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpycrfsuite\\_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.append\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pycrfsuite\\_pycrfsuite.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mvector.from_py.__pyx_convert_vector_from_py_std_3a__3a_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm = 'l2sgd',\n",
    "    c2 = 0.1,\n",
    "    max_iterations = 100,\n",
    "    all_possible_transitions = True\n",
    ")\n",
    "crf.fit(X_train1, y_train1)\n",
    "\n",
    "y_pred = crf.predict(X_test1)\n",
    "metrics.flat_f1_score(y_test1, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type() takes 1 or 3 arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-6df2063987fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: type() takes 1 or 3 arguments"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
